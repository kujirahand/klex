// This file is auto-generated by build.rs
// Do not edit manually
// --------------------------------------------------------
// Generated from: tests/test_any_chars.klex

use regex::Regex;
use std::collections::HashMap;

// Token kind constants
pub const WHITESPACE: u32 = 0;
pub const AT_SYMBOL: u32 = 1;
pub const EXCLAMATION: u32 = 2;
pub const ANY_CHAR: u32 = 3;
pub const ANY_CHAR_PLUS: u32 = 4;

pub const UNKNOWN_TOKEN: u32 = u32::MAX; // For unmatched characters

/// Token structure that represents a lexical token
#[derive(Debug, Clone, PartialEq)]
pub struct Token {
    pub kind: u32,
    pub value: String,
    pub row: usize,
    pub col: usize,
    pub length: usize,
    pub indent: usize,
    pub tag: isize,
}

impl Token {
    pub fn new(
        kind: u32,
        value: String,
        row: usize,
        col: usize,
        length: usize,
        indent: usize,
    ) -> Self {
        Token {
            kind,
            value,
            row,
            col,
            length,
            indent,
            tag: 0,
        }
    }
}

pub struct Lexer {
    input: String,
    pos: usize,
    row: usize,
    col: usize,
    regex_cache: HashMap<u32, Regex>,
    last_token_kind: Option<u32>,
}

impl Lexer {
    pub fn new(input: String) -> Self {
        let mut regex_cache = HashMap::new();
        // Pre-compile all patterns and store them in cache
        regex_cache.insert(0, Regex::new("^[ \\t]+").unwrap());
        regex_cache.insert(1, Regex::new("^@").unwrap());
        regex_cache.insert(2, Regex::new("^!").unwrap());
        regex_cache.insert(3, Regex::new("^.").unwrap());
        regex_cache.insert(4, Regex::new("^.+").unwrap());

        Lexer {
            input,
            pos: 0,
            row: 1,
            col: 1,
            regex_cache,
            last_token_kind: None,
        }
    }

    pub fn next_token(&mut self) -> Option<Token> {
        if self.pos >= self.input.len() {
            return None;
        }

        let remaining = &self.input[self.pos..];
        let start_row = self.row;
        let start_col = self.col;

        // Calculate indent (spaces at the start of current line)
        let indent = self.calculate_line_indent();

        // Rule: [ \t]+ -> WHITESPACE
        if let Some(matched) = self.match_cached_pattern(remaining, 0) {
            let token = Token::new(
                0,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            // Whitespace tokens don't update context;
            return Some(token);
        }

        // Rule: @ -> AT_SYMBOL
        if let Some(matched) = self.match_cached_pattern(remaining, 1) {
            let token = Token::new(
                1,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: ! -> EXCLAMATION
        if let Some(matched) = self.match_cached_pattern(remaining, 2) {
            let token = Token::new(
                2,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: . -> ANY_CHAR
        if let Some(matched) = self.match_cached_pattern(remaining, 3) {
            let token = Token::new(
                3,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: .+ -> ANY_CHAR_PLUS
        if let Some(matched) = self.match_cached_pattern(remaining, 4) {
            let token = Token::new(
                4,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // No pattern matched, consume one character
        let ch = remaining.chars().next().unwrap();
        let matched = ch.to_string();
        self.advance(&matched);
        let token = Token::new(UNKNOWN_TOKEN, matched, start_row, start_col, 1, indent);
        self.last_token_kind = Some(token.kind);
        Some(token)
    }

    fn calculate_line_indent(&self) -> usize {
        // Find the start of the current line
        let mut line_start = 0;
        let mut pos = 0;

        // Find the beginning of the current line
        while pos < self.pos {
            if self.input.chars().nth(pos) == Some('\n') {
                line_start = pos + 1;
            }
            pos += 1;
        }

        // Count spaces from the beginning of the line
        let line_content = &self.input[line_start..];
        line_content.chars().take_while(|&c| c == ' ').count()
    }

    fn match_cached_pattern(&self, input: &str, token_kind: u32) -> Option<String> {
        if let Some(regex) = self.regex_cache.get(&token_kind) {
            if let Some(mat) = regex.find(input) {
                return Some(mat.as_str().to_string());
            }
        }
        None
    }

    fn advance(&mut self, matched: &str) {
        for ch in matched.chars() {
            self.pos += ch.len_utf8();
            if ch == '\n' {
                self.row += 1;
                self.col = 1;
            } else {
                self.col += 1;
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_any_char_patterns() {
        // Test with characters that won't conflict with other patterns
        let input = "$ ###".to_string();
        let mut lexer = Lexer::new(input);

        // Debug: print what tokens we get
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            println!("Token: kind={}, value='{}'", token.kind, token.value);
            tokens.push(token);
        }

        // Find specific tokens
        assert!(tokens.iter().any(|t| t.kind == ANY_CHAR && t.value == "$"));
        assert!(tokens
            .iter()
            .any(|t| t.kind == WHITESPACE && t.value == " "));
        // ANY_CHAR_PLUS might match the first '#' or all "###" depending on implementation
        assert!(
            tokens.iter().any(|t| t.kind == ANY_CHAR && t.value == "#")
                || tokens
                    .iter()
                    .any(|t| t.kind == ANY_CHAR_PLUS && t.value == "###")
        );
    }
}
