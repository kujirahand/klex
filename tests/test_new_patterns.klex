use std::collections::HashMap;

%%
// Test character literal
'q' -> CHAR_Q
'w' -> CHAR_W

// Test string literal  
"hello" -> HELLO_STRING
"world" -> WORLD_STRING

// Test character range syntax  
[0-9]+ -> DIGIT_RANGE
[A-Z]+ -> UPPER_CASE
[a-z]+ -> LOWER_CASE

// Test character set syntax
[abc]+ -> ABC_SET
[xyz]+ -> XYZ_SET

// Test regular expression (more specific patterns)
/[a-zA-Z_][a-zA-Z0-9_]*/ -> IDENTIFIER

// Test whitespace for separation (must come before other patterns)
/[ \t]+/ -> WHITESPACE

// Basic escaped character test (complex tests in separate file)
\+ -> PLUS_ESCAPED

// Test choice
'-' -> MINUS_SIGN
("true"|"false") -> BOOLEAN

// Basic any character test (complex tests in separate file)
/[^a-zA-Z0-9 \t\n+x-]/ -> SPECIAL_CHAR

// Test action with new patterns
'x' -> { println!("Found x character"); Some(Token::new(999, test_t.value.clone(), test_t.row, test_t.col, test_t.length, test_t.indent)) }
%%

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_new_patterns() {
        let input = "q hello 123 ABC abc xyz x".to_string();
        let mut lexer = Lexer::new(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            tokens.push(token);
        }
        
        // Check that we got some tokens
        assert!(!tokens.is_empty());
        println!("Generated {} tokens", tokens.len());
        for token in &tokens {
            println!("Token: kind={}, value='{}'", token.kind, token.value);
        }

        // Test specific patterns
        assert!(tokens.iter().any(|t| t.value == "q" && t.kind == CHAR_Q));
        assert!(tokens.iter().any(|t| t.value == "hello" && t.kind == HELLO_STRING));
        assert!(tokens.iter().any(|t| t.value == "123" && t.kind == DIGIT_RANGE));
        assert!(tokens.iter().any(|t| t.value == "ABC" && t.kind == UPPER_CASE));
        // abc matches LOWER_CASE pattern first since it comes before ABC_SET in rule order
        assert!(tokens.iter().any(|t| t.value == "abc" && t.kind == LOWER_CASE));
    }
    
    #[test]
    fn test_character_ranges_and_sets() {
        let input = "123 def XYZ xyz".to_string();
        let mut lexer = Lexer::new(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            tokens.push(token);
        }
        
        println!("Character ranges test tokens:");
        for token in &tokens {
            println!("Token: kind={}, value='{}'", token.kind, token.value);
        }
        
        // Should match digit range, lower case, upper case, and character sets
        assert!(tokens.iter().any(|t| t.kind == DIGIT_RANGE));
        assert!(tokens.iter().any(|t| t.kind == LOWER_CASE));
        assert!(tokens.iter().any(|t| t.kind == UPPER_CASE));
        // xyz's 'x' matches action rule first, so we check for any LOWER_CASE match
        assert!(tokens.iter().any(|t| t.kind == LOWER_CASE && (t.value == "def" || t.value == "yz")));
    }
}