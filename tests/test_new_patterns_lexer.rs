// This file is auto-generated by build.rs
// Do not edit manually
// --------------------------------------------------------
// Generated from: tests/test_new_patterns.klex

use regex::Regex;
use std::collections::HashMap;

// Token kind constants
pub const CHAR_Q: u32 = 0;
pub const CHAR_W: u32 = 1;
pub const HELLO_STRING: u32 = 2;
pub const WORLD_STRING: u32 = 3;
pub const DIGIT_RANGE: u32 = 4;
pub const UPPER_CASE: u32 = 5;
pub const LOWER_CASE: u32 = 6;
pub const ABC_SET: u32 = 7;
pub const XYZ_SET: u32 = 8;
pub const IDENTIFIER: u32 = 9;
pub const WHITESPACE: u32 = 10;
pub const PLUS_ESCAPED: u32 = 11;
pub const MINUS_SIGN: u32 = 12;
pub const BOOLEAN: u32 = 13;
pub const SPECIAL_CHAR: u32 = 14;


pub const UNKNOWN_TOKEN: u32 = u32::MAX; // For unmatched characters

/// Token structure that represents a lexical token
#[derive(Debug, Clone, PartialEq)]
pub struct Token {
	pub kind: u32,
	pub value: String,
	pub row: usize,
	pub col: usize,
	pub length: usize,
	pub indent: usize,
	pub tag: isize,
}

impl Token {
	pub fn new(kind: u32, value: String, row: usize, col: usize, length: usize, indent: usize) -> Self {
		Token {
			kind,
			value,
			row,
			col,
			length,
			indent,
			tag: 0,
		}
	}
}

pub struct Lexer {
	input: String,
	pos: usize,
	row: usize,
	col: usize,
	regex_cache: HashMap<u32, Regex>,
	last_token_kind: Option<u32>,
}

impl Lexer {
	pub fn new(input: String) -> Self {
		let mut regex_cache = HashMap::new();
		        // Pre-compile all patterns and store them in cache
        regex_cache.insert(0, Regex::new("^q").unwrap());
        regex_cache.insert(1, Regex::new("^w").unwrap());
        regex_cache.insert(2, Regex::new("^hello").unwrap());
        regex_cache.insert(3, Regex::new("^world").unwrap());
        regex_cache.insert(4, Regex::new("^[0-9]+").unwrap());
        regex_cache.insert(5, Regex::new("^[A-Z]+").unwrap());
        regex_cache.insert(6, Regex::new("^[a-z]+").unwrap());
        regex_cache.insert(7, Regex::new("^[abc]+").unwrap());
        regex_cache.insert(8, Regex::new("^[xyz]+").unwrap());
        regex_cache.insert(9, Regex::new("^[a-zA-Z_][a-zA-Z0-9_]*").unwrap());
        regex_cache.insert(10, Regex::new("^[ \\t]+").unwrap());
        regex_cache.insert(11, Regex::new("^\\+").unwrap());
        regex_cache.insert(12, Regex::new("^\\-").unwrap());
        regex_cache.insert(13, Regex::new("^(true|false)").unwrap());
        regex_cache.insert(14, Regex::new("^[^a-zA-Z0-9 \\t\\n+x-]").unwrap());
        regex_cache.insert(15, Regex::new("^x").unwrap());
        
		Lexer {
			input,
			pos: 0,
			row: 1,
			col: 1,
			regex_cache,
			last_token_kind: None,
		}
	}

	pub fn next_token(&mut self) -> Option<Token> {
		if self.pos >= self.input.len() {
			return None;
		}

		let remaining = &self.input[self.pos..];
		let start_row = self.row;
		let start_col = self.col;

		// Calculate indent (spaces at the start of current line)
		let indent = self.calculate_line_indent();

		        // Action rule: x -> { println!("Found x character"); Some(Token::new(999, test_t.value.clone(), test_t.row, test_t.col, test_t.length, test_t.indent)) }
        if let Some(matched) = self.match_cached_pattern(remaining, 15) {
            let matched_str = matched.clone();
            // Create token for action code to use
            let test_t = Token::new(
                15,
                matched_str.clone(),
                start_row,
                start_col,
                matched_str.len(),
                indent,
            );
            self.advance(&matched_str);
            // Execute action code with available variables
            let action_result: Option<Token> = {
                println!("Found x character"); Some(Token::new(999, test_t.value.clone(), test_t.row, test_t.col, test_t.length, test_t.indent))
            };
            if let Some(token) = action_result {
                self.last_token_kind = Some(token.kind);
                return Some(token);
            } else {
                // Continue to next iteration if no token was returned from action
                return self.next_token();
            }
        }

        // Rule: q -> CHAR_Q
        if let Some(matched) = self.match_cached_pattern(remaining, 0) {
            let token = Token::new(
                0,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: w -> CHAR_W
        if let Some(matched) = self.match_cached_pattern(remaining, 1) {
            let token = Token::new(
                1,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: hello -> HELLO_STRING
        if let Some(matched) = self.match_cached_pattern(remaining, 2) {
            let token = Token::new(
                2,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: world -> WORLD_STRING
        if let Some(matched) = self.match_cached_pattern(remaining, 3) {
            let token = Token::new(
                3,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [0-9]+ -> DIGIT_RANGE
        if let Some(matched) = self.match_cached_pattern(remaining, 4) {
            let token = Token::new(
                4,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [A-Z]+ -> UPPER_CASE
        if let Some(matched) = self.match_cached_pattern(remaining, 5) {
            let token = Token::new(
                5,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [a-z]+ -> LOWER_CASE
        if let Some(matched) = self.match_cached_pattern(remaining, 6) {
            let token = Token::new(
                6,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [abc]+ -> ABC_SET
        if let Some(matched) = self.match_cached_pattern(remaining, 7) {
            let token = Token::new(
                7,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [xyz]+ -> XYZ_SET
        if let Some(matched) = self.match_cached_pattern(remaining, 8) {
            let token = Token::new(
                8,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [a-zA-Z_][a-zA-Z0-9_]* -> IDENTIFIER
        if let Some(matched) = self.match_cached_pattern(remaining, 9) {
            let token = Token::new(
                9,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [ \t]+ -> WHITESPACE
        if let Some(matched) = self.match_cached_pattern(remaining, 10) {
            let token = Token::new(
                10,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            // Whitespace tokens don't update context;
            return Some(token);
        }

        // Rule: \+ -> PLUS_ESCAPED
        if let Some(matched) = self.match_cached_pattern(remaining, 11) {
            let token = Token::new(
                11,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: \- -> MINUS_SIGN
        if let Some(matched) = self.match_cached_pattern(remaining, 12) {
            let token = Token::new(
                12,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: (true|false) -> BOOLEAN
        if let Some(matched) = self.match_cached_pattern(remaining, 13) {
            let token = Token::new(
                13,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [^a-zA-Z0-9 \t\n+x-] -> SPECIAL_CHAR
        if let Some(matched) = self.match_cached_pattern(remaining, 14) {
            let token = Token::new(
                14,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }



		// No pattern matched, consume one character
		let ch = remaining.chars().next().unwrap();
		let matched = ch.to_string();
		self.advance(&matched);
		let token = Token::new(UNKNOWN_TOKEN, matched, start_row, start_col, 1, indent);
		self.last_token_kind = Some(token.kind);
		Some(token)
	}

	fn calculate_line_indent(&self) -> usize {
		// Find the start of the current line
		let mut line_start = 0;
		let mut pos = 0;
		
		// Find the beginning of the current line
		while pos < self.pos {
			if self.input.chars().nth(pos) == Some('\n') {
				line_start = pos + 1;
			}
			pos += 1;
		}
		
		// Count spaces from the beginning of the line
		let line_content = &self.input[line_start..];
		line_content.chars().take_while(|&c| c == ' ').count()
	}

	fn match_cached_pattern(&self, input: &str, token_kind: u32) -> Option<String> {
		if let Some(regex) = self.regex_cache.get(&token_kind) {
			if let Some(mat) = regex.find(input) {
				return Some(mat.as_str().to_string());
			}
		}
		None
	}

	fn advance(&mut self, matched: &str) {
		for ch in matched.chars() {
			self.pos += ch.len_utf8();
			if ch == '\n' {
				self.row += 1;
				self.col = 1;
			} else {
				self.col += 1;
			}
		}
	}
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_new_patterns() {
        let input = "q hello 123 ABC abc xyz x".to_string();
        let mut lexer = Lexer::new(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            tokens.push(token);
        }
        
        // Check that we got some tokens
        assert!(!tokens.is_empty());
        println!("Generated {} tokens", tokens.len());
        for token in &tokens {
            println!("Token: kind={}, value='{}'", token.kind, token.value);
        }

        // Test specific patterns
        assert!(tokens.iter().any(|t| t.value == "q" && t.kind == CHAR_Q));
        assert!(tokens.iter().any(|t| t.value == "hello" && t.kind == HELLO_STRING));
        assert!(tokens.iter().any(|t| t.value == "123" && t.kind == DIGIT_RANGE));
        assert!(tokens.iter().any(|t| t.value == "ABC" && t.kind == UPPER_CASE));
        // abc matches LOWER_CASE pattern first since it comes before ABC_SET in rule order
        assert!(tokens.iter().any(|t| t.value == "abc" && t.kind == LOWER_CASE));
    }
    
    #[test]
    fn test_character_ranges_and_sets() {
        let input = "123 def XYZ xyz".to_string();
        let mut lexer = Lexer::new(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            tokens.push(token);
        }
        
        println!("Character ranges test tokens:");
        for token in &tokens {
            println!("Token: kind={}, value='{}'", token.kind, token.value);
        }
        
        // Should match digit range, lower case, upper case, and character sets
        assert!(tokens.iter().any(|t| t.kind == DIGIT_RANGE));
        assert!(tokens.iter().any(|t| t.kind == LOWER_CASE));
        assert!(tokens.iter().any(|t| t.kind == UPPER_CASE));
        // xyz's 'x' matches action rule first, so we check for any LOWER_CASE match
        assert!(tokens.iter().any(|t| t.kind == LOWER_CASE && (t.value == "def" || t.value == "yz")));
    }
}
