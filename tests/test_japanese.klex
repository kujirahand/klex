// Test for Japanese characters (hiragana, katakana, kanji)
use regex::Regex;
use std::collections::HashMap;

%%
// Japanese character patterns
[ã-ã‚“]+ -> Hiragana
[ã‚¡-ãƒ¶ãƒ¼]+ -> Katakana
[ä¸€-é¾¯ã€…]+ -> Kanji
// Emoji patterns (various Unicode emoji ranges)
[\u{1F600}-\u{1F64F}]+ -> EmojiEmoticons
[\u{1F300}-\u{1F5FF}]+ -> EmojiSymbols
[\u{1F680}-\u{1F6FF}]+ -> EmojiTransport
[\u{1F900}-\u{1F9FF}]+ -> EmojiSupplemental
[\u{2600}-\u{26FF}]+ -> EmojiMisc
[\u{2700}-\u{27BF}]+ -> EmojiDingbats
[a-zA-Z]+ -> Alphabet
[0-9]+ -> Number
[ \t]+ -> Whitespace
\n -> Newline
%%
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hiragana() {
        // Test hiragana characters
        let input = "ã²ã‚‰ãŒãª";
        let mut lexer = Lexer::from_str(input);
        
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, TokenKind::Hiragana);
        assert_eq!(token.text, "ã²ã‚‰ãŒãª");
    }

    #[test]
    fn test_katakana() {
        // Test katakana characters
        let input = "ã‚«ã‚¿ã‚«ãƒŠ";
        let mut lexer = Lexer::from_str(input);
        
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, TokenKind::Katakana);
        assert_eq!(token.text, "ã‚«ã‚¿ã‚«ãƒŠ");
    }

    #[test]
    fn test_kanji() {
        // Test kanji characters
        let input = "æ¼¢å­—";
        let mut lexer = Lexer::from_str(input);
        
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, TokenKind::Kanji);
        assert_eq!(token.text, "æ¼¢å­—");
    }

    #[test]
    fn test_mixed_japanese() {
        // Test mixed Japanese text
        let input = "ã“ã‚Œã¯ã‚«ã‚¿ã‚«ãƒŠã¨æ¼¢å­—ã®ãƒ†ã‚¹ãƒˆ";
        let mut lexer = Lexer::from_str(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            println!("Token: kind={:?}, value='{}'", token.kind, token.text);
            tokens.push(token);
        }
        
        // Verify we found hiragana, katakana, and kanji tokens
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Hiragana));
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Katakana));
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Kanji));
    }

    #[test]
    fn test_japanese_with_numbers() {
        // Test Japanese with numbers
        let input = "ä»¤å’Œ5å¹´";
        let mut lexer = Lexer::from_str(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            println!("Token: kind={:?}, value='{}'", token.kind, token.text);
            tokens.push(token);
        }
        
        // Should have kanji and number tokens
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Kanji && t.text == "ä»¤å’Œ"));
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Number && t.text == "5"));
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Kanji && t.text == "å¹´"));
    }

    #[test]
    fn test_japanese_with_spaces() {
        // Test Japanese with whitespace
        let input = "ã“ã‚“ã«ã¡ã¯ ä¸–ç•Œ";
        let mut lexer = Lexer::from_str(input);
        
        let token1 = lexer.next_token().unwrap();
        assert_eq!(token1.kind, TokenKind::Hiragana);
        assert_eq!(token1.text, "ã“ã‚“ã«ã¡ã¯");
        
        let token2 = lexer.next_token().unwrap();
        assert_eq!(token2.kind, TokenKind::Whitespace);
        
        let token3 = lexer.next_token().unwrap();
        assert_eq!(token3.kind, TokenKind::Kanji);
        assert_eq!(token3.text, "ä¸–ç•Œ");
    }

    #[test]
    fn test_all_japanese_character_types() {
        // Test all three Japanese character types together
        let input = "ã‚ã„ã†ãˆãŠ ã‚¢ã‚¤ã‚¦ã‚¨ã‚ª äººé¡æ„›";
        let mut lexer = Lexer::from_str(input);
        
        let token1 = lexer.next_token().unwrap();
        assert_eq!(token1.kind, TokenKind::Hiragana);
        assert_eq!(token1.text, "ã‚ã„ã†ãˆãŠ");
        
        let _ws1 = lexer.next_token().unwrap(); // whitespace
        
        let token2 = lexer.next_token().unwrap();
        assert_eq!(token2.kind, TokenKind::Katakana);
        assert_eq!(token2.text, "ã‚¢ã‚¤ã‚¦ã‚¨ã‚ª");
        
        let _ws2 = lexer.next_token().unwrap(); // whitespace
        
        let token3 = lexer.next_token().unwrap();
        assert_eq!(token3.kind, TokenKind::Kanji);
        assert_eq!(token3.text, "äººé¡æ„›");
    }

    #[test]
    fn test_emoji_emoticons() {
        // Test emoji emoticons (face emojis)
        let input = "ğŸ˜€ğŸ˜ƒğŸ˜„";
        let mut lexer = Lexer::from_str(input);
        
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, TokenKind::EmojiEmoticons);
        assert_eq!(token.text, "ğŸ˜€ğŸ˜ƒğŸ˜„");
    }

    #[test]
    fn test_emoji_symbols() {
        // Test emoji symbols (weather, nature, etc.)
        let input = "ğŸŒğŸŒ™â­";
        let mut lexer = Lexer::from_str(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            println!("Token: kind={:?}, value='{}'", token.kind, token.text);
            tokens.push(token);
        }
        
        // Should find emoji tokens
        assert!(tokens.iter().any(|t| matches!(t.kind, TokenKind::EmojiSymbols | TokenKind::EmojiMisc)));
    }

    #[test]
    fn test_emoji_transport() {
        // Test emoji transport symbols
        let input = "ğŸš€ğŸšğŸš‚";
        let mut lexer = Lexer::from_str(input);
        
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, TokenKind::EmojiTransport);
        assert_eq!(token.text, "ğŸš€ğŸšğŸš‚");
    }

    #[test]
    fn test_japanese_with_emoji() {
        // Test Japanese text mixed with emojis
        let input = "ã“ã‚“ã«ã¡ã¯ğŸ˜€ä¸–ç•ŒğŸŒ";
        let mut lexer = Lexer::from_str(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            println!("Token: kind={:?}, value='{}'", token.kind, token.text);
            tokens.push(token);
        }
        
        // Should have hiragana, emoji, and kanji tokens
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Hiragana));
        assert!(tokens.iter().any(|t| matches!(t.kind, 
            TokenKind::EmojiEmoticons | 
            TokenKind::EmojiSymbols | 
            TokenKind::EmojiTransport | 
            TokenKind::EmojiSupplemental |
            TokenKind::EmojiMisc |
            TokenKind::EmojiDingbats)));
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Kanji));
    }

    #[test]
    fn test_emoji_with_text() {
        // Test emoji mixed with various text types
        let input = "Hello ğŸ˜Š ã“ã‚“ã«ã¡ã¯ ğŸ‰ ã‚«ã‚¿ã‚«ãƒŠ âœ¨";
        let mut lexer = Lexer::from_str(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            println!("Token: kind={:?}, value='{}'", token.kind, token.text);
            tokens.push(token);
        }
        
        // Verify different token types
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Alphabet));
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Hiragana));
        assert!(tokens.iter().any(|t| t.kind == TokenKind::Katakana));
        assert!(tokens.iter().any(|t| matches!(t.kind, 
            TokenKind::EmojiEmoticons | 
            TokenKind::EmojiSymbols | 
            TokenKind::EmojiMisc)));
    }

    #[test]
    fn test_multiple_emoji_types() {
        // Test different types of emojis together
        let input = "ğŸ˜€ğŸŒŸğŸš€";
        let mut lexer = Lexer::from_str(input);
        
        let mut tokens = Vec::new();
        while let Some(token) = lexer.next_token() {
            println!("Token: kind={:?}, value='{}'", token.kind, token.text);
            tokens.push(token);
        }
        
        // Should find various emoji tokens
        assert!(!tokens.is_empty());
        assert!(tokens.iter().all(|t| matches!(t.kind, 
            TokenKind::EmojiEmoticons | 
            TokenKind::EmojiSymbols | 
            TokenKind::EmojiTransport | 
            TokenKind::EmojiMisc)));
    }
}

