// This file is auto-generated by build.rs
// Do not edit manually
// --------------------------------------------------------
// Generated from: tests/test_context.klex

use regex::Regex;
use std::collections::HashMap;

// Token kind constants
pub const IDENTIFIER: u32 = 0;
pub const NUMBER: u32 = 1;
pub const PLUS: u32 = 2;
pub const MINUS: u32 = 3;
pub const WHITESPACE: u32 = 4;
pub const NEWLINE: u32 = 5;
pub const INDEXED_NUMBER: u32 = 6;
pub const POSITIVE_NUMBER: u32 = 7;


pub const UNKNOWN_TOKEN: u32 = u32::MAX; // For unmatched characters

/// Token structure that represents a lexical token
#[derive(Debug, Clone, PartialEq)]
pub struct Token {
	pub kind: u32,
	pub value: String,
	pub row: usize,
	pub col: usize,
	pub length: usize,
	pub indent: usize,
	pub tag: isize,
}

impl Token {
	pub fn new(kind: u32, value: String, row: usize, col: usize, length: usize, indent: usize) -> Self {
		Token {
			kind,
			value,
			row,
			col,
			length,
			indent,
			tag: 0,
		}
	}
}

pub struct Lexer {
	input: String,
	pos: usize,
	row: usize,
	col: usize,
	regex_cache: HashMap<u32, Regex>,
	last_token_kind: Option<u32>,
}

impl Lexer {
	pub fn new(input: String) -> Self {
		let mut regex_cache = HashMap::new();
		        // Pre-compile all patterns and store them in cache
        regex_cache.insert(0, Regex::new("^[a-zA-Z_][a-zA-Z0-9_]*").unwrap());
        regex_cache.insert(1, Regex::new("^[0-9]+").unwrap());
        regex_cache.insert(2, Regex::new("^\\+").unwrap());
        regex_cache.insert(3, Regex::new("^\\-").unwrap());
        regex_cache.insert(4, Regex::new("^[ \\t]+").unwrap());
        regex_cache.insert(5, Regex::new("^
").unwrap());
        regex_cache.insert(6, Regex::new("^[0-9]+").unwrap());
        regex_cache.insert(7, Regex::new("^[0-9]+").unwrap());
        
		Lexer {
			input,
			pos: 0,
			row: 1,
			col: 1,
			regex_cache,
			last_token_kind: None,
		}
	}

	pub fn next_token(&mut self) -> Option<Token> {
		if self.pos >= self.input.len() {
			return None;
		}

		let remaining = &self.input[self.pos..];
		let start_row = self.row;
		let start_col = self.col;

		// Calculate indent (spaces at the start of current line)
		let indent = self.calculate_line_indent();

		        // Context-dependent rule: [0-9]+ -> INDEXED_NUMBER (after IDENTIFIER)
        if self.last_token_kind == Some(0) {
            if let Some(matched) = self.match_cached_pattern(remaining, 6) {
                let token = Token::new(
                    6,
                    matched.clone(),
                    start_row,
                    start_col,
                    matched.len(),
                    indent,
                );
                self.advance(&matched);
                self.last_token_kind = Some(token.kind);
                return Some(token);
            }
        }

        // Context-dependent rule: [0-9]+ -> POSITIVE_NUMBER (after PLUS)
        if self.last_token_kind == Some(2) {
            if let Some(matched) = self.match_cached_pattern(remaining, 7) {
                let token = Token::new(
                    7,
                    matched.clone(),
                    start_row,
                    start_col,
                    matched.len(),
                    indent,
                );
                self.advance(&matched);
                self.last_token_kind = Some(token.kind);
                return Some(token);
            }
        }

        // Rule: [a-zA-Z_][a-zA-Z0-9_]* -> IDENTIFIER
        if let Some(matched) = self.match_cached_pattern(remaining, 0) {
            let token = Token::new(
                0,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [0-9]+ -> NUMBER
        if let Some(matched) = self.match_cached_pattern(remaining, 1) {
            let token = Token::new(
                1,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: \+ -> PLUS
        if let Some(matched) = self.match_cached_pattern(remaining, 2) {
            let token = Token::new(
                2,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: \- -> MINUS
        if let Some(matched) = self.match_cached_pattern(remaining, 3) {
            let token = Token::new(
                3,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            self.last_token_kind = Some(token.kind);
            return Some(token);
        }

        // Rule: [ \t]+ -> WHITESPACE
        if let Some(matched) = self.match_cached_pattern(remaining, 4) {
            let token = Token::new(
                4,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            // Whitespace tokens don't update context;
            return Some(token);
        }

        // Rule: \n -> NEWLINE
        if let Some(matched) = self.match_cached_pattern(remaining, 5) {
            let token = Token::new(
                5,
                matched.clone(),
                start_row,
                start_col,
                matched.len(),
                indent,
            );
            self.advance(&matched);
            // Whitespace tokens don't update context;
            return Some(token);
        }



		// No pattern matched, consume one character
		let ch = remaining.chars().next().unwrap();
		let matched = ch.to_string();
		self.advance(&matched);
		let token = Token::new(UNKNOWN_TOKEN, matched, start_row, start_col, 1, indent);
		self.last_token_kind = Some(token.kind);
		Some(token)
	}

	fn calculate_line_indent(&self) -> usize {
		// Find the start of the current line
		let mut line_start = 0;
		let mut pos = 0;
		
		// Find the beginning of the current line
		while pos < self.pos {
			if self.input.chars().nth(pos) == Some('\n') {
				line_start = pos + 1;
			}
			pos += 1;
		}
		
		// Count spaces from the beginning of the line
		let line_content = &self.input[line_start..];
		line_content.chars().take_while(|&c| c == ' ').count()
	}

	fn match_cached_pattern(&self, input: &str, token_kind: u32) -> Option<String> {
		if let Some(regex) = self.regex_cache.get(&token_kind) {
			if let Some(mat) = regex.find(input) {
				return Some(mat.as_str().to_string());
			}
		}
		None
	}

	fn advance(&mut self, matched: &str) {
		for ch in matched.chars() {
			self.pos += ch.len_utf8();
			if ch == '\n' {
				self.row += 1;
				self.col = 1;
			} else {
				self.col += 1;
			}
		}
	}
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_context_dependent_lexer() {
        let input = "var 123 +456 -789".to_string();
        let mut lexer = Lexer::new(input);
        
        // First token: IDENTIFIER
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, IDENTIFIER);
        assert_eq!(token.value, "var");
        
        // Second token: WHITESPACE
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, WHITESPACE);
        
        // Third token: INDEXED_NUMBER (context-dependent after IDENTIFIER)
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, INDEXED_NUMBER);
        assert_eq!(token.value, "123");
        
        // Fourth token: WHITESPACE
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, WHITESPACE);
        
        // Fifth token: PLUS
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, PLUS);
        assert_eq!(token.value, "+");
        
        // Sixth token: POSITIVE_NUMBER (context-dependent after PLUS)
        let token = lexer.next_token().unwrap();
        assert_eq!(token.kind, POSITIVE_NUMBER);
        assert_eq!(token.value, "456");
    }
}
